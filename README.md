# ðŸ‘• ViT: Making Fashion Pixels Trendy Again ðŸ‘—
Because even AI deserves a fashion upgrade from boring CNNs!
## What's This Fashion-Forward Code About?
This project implements a Vision Transformer (ViT) model inspired by the groundbreaking paper "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" by Dosovitskiy et al. But instead of using it for something serious, we're using this computational powerhouse to decide if that pixelated blob is a sandal or an ankle boot. High fashion, am I right?
## ðŸ§  The Secret Sauce
Remember when everyone said "you need convolutions for images"? Well, this ViT model says "hold my gradient tape" and processes Fashion MNIST using only self-attention. It chops up those stylish 28Ã—28 grayscale masterpieces into 4Ã—4 patches (fashion squares, if you will), and lets transformers do their magic.

## ðŸš€ How To Make Your Computer Recognize Fashion

1. Clone this repo faster than a fast-fashion brand copies runway designs
2. Run:
   ```shell
    python training.py
   ```
    

4. Watch your GPU sweat through 5 epochs
